{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zEZSQoeg4CL",
        "outputId": "37b3d0e4-6658-4ae5-e6d6-02e5d9ed8977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sympy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "toSDgmBpXN4E",
        "outputId": "faff6894-e8e9-4f4f-93e6-d3a5e7b975c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy"
                ]
              },
              "id": "b769f9e0cd26459b87889a2ea92419c3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN7mmJwdENDD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque, namedtuple\n",
        "\n",
        "# Define map elements\n",
        "EMPTY = 0\n",
        "WALL = 1\n",
        "LAVA = 2\n",
        "TREASURE = 3\n",
        "EXIT = 4\n",
        "START = 5\n",
        "ENEMY = 6\n",
        "\n",
        "# Define Colors for Visualization\n",
        "COLOR_MAP = {\n",
        "    EMPTY: \"white\",\n",
        "    WALL: \"brown\",\n",
        "    LAVA: \"red\",\n",
        "    TREASURE: \"yellow\",\n",
        "    EXIT: \"green\",\n",
        "    START: \"blue\",\n",
        "    ENEMY: \"purple\",\n",
        "}\n",
        "\n",
        "# Experience replay buffer\n",
        "Experience = namedtuple('Experience', ['state', 'action', 'reward', 'next_state', 'done'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0uoMw7qEYpM"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=5000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append(Experience(state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        experiences = random.sample(self.buffer, k=batch_size)\n",
        "        states = torch.stack([torch.tensor(e.state, dtype=torch.float) for e in experiences])\n",
        "        actions = torch.tensor([e.action for e in experiences])\n",
        "        rewards = torch.tensor([e.reward for e in experiences], dtype=torch.float)\n",
        "        next_states = torch.stack([torch.tensor(e.next_state, dtype=torch.float) for e in experiences])\n",
        "        dones = torch.tensor([e.done for e in experiences], dtype=torch.float)\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3LPcSUywcvs"
      },
      "outputs": [],
      "source": [
        "class DQNModel(nn.Module):\n",
        "    \"\"\"Lightweight Q-Network\"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H56s7G70ZnYM"
      },
      "outputs": [],
      "source": [
        "class DungeonAgent:\n",
        "    \"\"\"Agent that learns to generate levels\"\"\"\n",
        "    def __init__(self, state_size, action_size, seed=42):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qnetwork = DQNModel(state_size, action_size).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork.parameters(), lr=0.001)\n",
        "        self.memory = ReplayBuffer(5000)\n",
        "\n",
        "        self.batch_size = 32\n",
        "        self.gamma = 0.99\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.999995\n",
        "        self.epsilon_min = 0.000001\n",
        "\n",
        "    def act(self, state, eval_mode=False):\n",
        "        if not eval_mode and random.random() < self.epsilon:\n",
        "            return random.randint(0, self.action_size - 1)\n",
        "\n",
        "        state = torch.tensor(state, dtype=torch.float, device=self.device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork(state)\n",
        "\n",
        "        if eval_mode and random.random() < 0.2:\n",
        "            return random.randint(0, self.action_size - 1)\n",
        "\n",
        "        return torch.argmax(action_values).item()\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        self.memory.push(state, action, reward, next_state, done)\n",
        "        if len(self.memory) > self.batch_size:\n",
        "            self.learn(self.memory.sample(self.batch_size))\n",
        "\n",
        "    def learn(self, experiences):\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        states = states.to(self.device)\n",
        "        actions = actions.to(self.device)\n",
        "        rewards = rewards.to(self.device)\n",
        "        next_states = next_states.to(self.device)\n",
        "        dones = dones.to(self.device)\n",
        "\n",
        "        Q_expected = self.qnetwork(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "        Q_targets = rewards + (self.gamma * self.qnetwork(next_states).max(1)[0] * (1 - dones))\n",
        "\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJaRmN-3_coH"
      },
      "outputs": [],
      "source": [
        "class DungeonEnvironment:\n",
        "    def __init__(self, difficulty=5, board_size=20):\n",
        "        self.board_size = board_size\n",
        "        self.difficulty = difficulty\n",
        "        self.max_enemies = 4\n",
        "\n",
        "        self.element_types = [EMPTY, WALL, LAVA, TREASURE, EXIT, START, ENEMY]\n",
        "        self.placement_types = [LAVA, TREASURE, ENEMY, WALL, EMPTY]\n",
        "\n",
        "        self.grid = np.zeros((board_size, board_size), dtype=np.int8)\n",
        "        self.cursor = None\n",
        "        self.start_pos = None\n",
        "        self.exit_pos = None\n",
        "        self.steps = 0\n",
        "        self.max_steps = 400\n",
        "\n",
        "        self._setup_playable_area()\n",
        "\n",
        "    def _setup_playable_area(self):\n",
        "        \"\"\"Define and fill the playable area based on difficulty.\"\"\"\n",
        "        # Scale playable area size with difficulty\n",
        "        min_playable = 5\n",
        "        max_playable = 18\n",
        "        playable_size = min_playable + (self.difficulty - 1) * (max_playable - min_playable) // 9\n",
        "        self.playable_width = self.playable_height = playable_size\n",
        "\n",
        "        # Center the playable area\n",
        "        self.playable_start_x = (self.board_size - self.playable_width) // 2\n",
        "        self.playable_start_y = (self.board_size - self.playable_height) // 2\n",
        "        self.playable_end_x = self.playable_start_x + self.playable_width - 1\n",
        "        self.playable_end_y = self.playable_start_y + self.playable_height - 1\n",
        "\n",
        "        self.object_counts = {k: 0 for k in self.placement_types}\n",
        "\n",
        "    def reset(self):\n",
        "        self.grid = np.zeros((self.board_size, self.board_size), dtype=int)\n",
        "        self.steps = 0\n",
        "        self._setup_playable_area()\n",
        "\n",
        "        # Fill outer area with walls\n",
        "        for y in range(self.board_size):\n",
        "            for x in range(self.board_size):\n",
        "                if (\n",
        "                    x < self.playable_start_x or x > self.playable_end_x or\n",
        "                    y < self.playable_start_y or y > self.playable_end_y\n",
        "                ):\n",
        "                    self.grid[y][x] = WALL\n",
        "\n",
        "        # Place START and EXIT inside playable area\n",
        "        positions = [\n",
        "            (x, y)\n",
        "            for y in range(self.playable_start_y + 1, self.playable_end_y)\n",
        "            for x in range(self.playable_start_x + 1, self.playable_end_x)\n",
        "        ]\n",
        "        self.start_pos = random.choice(positions)\n",
        "        positions.remove(self.start_pos)\n",
        "        self.exit_pos = random.choice(positions)\n",
        "\n",
        "        self.grid[self.start_pos[1]][self.start_pos[0]] = START\n",
        "        self.grid[self.exit_pos[1]][self.exit_pos[0]] = EXIT\n",
        "\n",
        "        self.cursor = list(self.start_pos)\n",
        "        self.object_counts = {k: 0 for k in self.placement_types}\n",
        "        self.visited = {tuple(self.cursor)}\n",
        "\n",
        "        # Determine playable interior area\n",
        "        playable_area = (self.playable_width - 2) * (self.playable_height - 2)\n",
        "\n",
        "        # ✅ New logic for treasure limit\n",
        "        max_treasure = max(1, int(0.25 * (playable_area ** 0.5)) - (self.difficulty // 2))\n",
        "        max_treasure = min(max_treasure, 10)\n",
        "\n",
        "        # ✅ Lava and wall density updates\n",
        "        lava_density = 0.01 + 0.005 * self.difficulty\n",
        "        wall_density = 0.2 + 0.02 * self.difficulty\n",
        "\n",
        "        max_lava = int(playable_area * lava_density)\n",
        "        max_internal_walls = int(playable_area * wall_density)\n",
        "\n",
        "        # ✅ Enemy tier rules (already implemented)\n",
        "        if self.difficulty <= 4:\n",
        "            self.allowed_enemy_limit = 1\n",
        "        elif self.difficulty <= 7:\n",
        "            self.allowed_enemy_limit = random.randint(2, 3)\n",
        "        else:\n",
        "            self.allowed_enemy_limit = 5\n",
        "\n",
        "        # Place objects\n",
        "        self._place_random_objects(TREASURE, max_treasure)\n",
        "        self._place_random_objects(LAVA, max_lava)\n",
        "        self._place_random_objects(ENEMY, self.allowed_enemy_limit)\n",
        "        self._place_random_objects(WALL, max_internal_walls)\n",
        "\n",
        "\n",
        "        return self._get_state()\n",
        "\n",
        "\n",
        "\n",
        "    def _place_random_objects(self, tile, count):\n",
        "        attempts = 0\n",
        "        placed = 0\n",
        "        max_attempts = count * 10\n",
        "\n",
        "        while placed < count and attempts < max_attempts:\n",
        "            x = random.randint(self.playable_start_x + 1, self.playable_end_x - 1)\n",
        "            y = random.randint(self.playable_start_y + 1, self.playable_end_y - 1)\n",
        "\n",
        "            if (x, y) not in [self.start_pos, self.exit_pos] and self.grid[y][x] == EMPTY:\n",
        "                self.grid[y][x] = tile\n",
        "                placed += 1\n",
        "                if tile in self.object_counts:\n",
        "                    self.object_counts[tile] += 1\n",
        "\n",
        "            attempts += 1\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self.steps += 1\n",
        "        reward = 0\n",
        "        done = False\n",
        "\n",
        "        if action < 4:\n",
        "            # Movement: up, down, left, right\n",
        "            dx, dy = [(0, -1), (0, 1), (-1, 0), (1, 0)][action]\n",
        "            new_x = min(max(self.cursor[0] + dx, self.playable_start_x + 1), self.playable_end_x - 1)\n",
        "            new_y = min(max(self.cursor[1] + dy, self.playable_start_y + 1), self.playable_end_y - 1)\n",
        "            self.cursor = [new_x, new_y]\n",
        "            reward -= 0.1  # discourage wandering\n",
        "        else:\n",
        "            tile = self.placement_types[action - 4]\n",
        "            cx, cy = self.cursor\n",
        "            current_tile = self.grid[cy][cx]\n",
        "\n",
        "            if (cx, cy) not in [self.start_pos, self.exit_pos]:\n",
        "                # Adjust old object count\n",
        "                if current_tile in self.object_counts:\n",
        "                    self.object_counts[current_tile] = max(0, self.object_counts[current_tile] - 1)\n",
        "\n",
        "                self.grid[cy][cx] = tile\n",
        "\n",
        "                # Apply tile placement logic\n",
        "                if tile == WALL:\n",
        "                    self.object_counts[WALL] += 1\n",
        "                    reward += 2\n",
        "                elif tile == TREASURE:\n",
        "                    self.object_counts[TREASURE] += 1\n",
        "                    reward += 3\n",
        "                elif tile == ENEMY:\n",
        "                    self.object_counts[ENEMY] += 1\n",
        "\n",
        "                    # ✅ Enforce enemy limit\n",
        "                    if self.object_counts[ENEMY] > self.allowed_enemy_limit:\n",
        "                        reward -= 10  # Heavy penalty\n",
        "                    else:\n",
        "                        reward += 4\n",
        "                elif tile == LAVA:\n",
        "                    self.object_counts[LAVA] += 1\n",
        "                    reward += 2\n",
        "                elif tile == EMPTY:\n",
        "                    reward -= 1\n",
        "\n",
        "        if self.steps >= self.max_steps:\n",
        "            done = True\n",
        "            reward += self._calculate_path_complexity() * 30\n",
        "\n",
        "        return self._get_state(), reward, done\n",
        "\n",
        "\n",
        "    def _get_state(self):\n",
        "        one_hot = np.zeros((self.board_size, self.board_size, len(self.element_types)), dtype=np.float32)\n",
        "        for y in range(self.board_size):\n",
        "            for x in range(self.board_size):\n",
        "                tile = self.grid[y][x]\n",
        "                one_hot[y, x, tile] = 1\n",
        "        flat = one_hot.flatten()\n",
        "        normalized_cursor = [self.cursor[0] / self.board_size, self.cursor[1] / self.board_size]\n",
        "        return np.concatenate([flat, normalized_cursor])\n",
        "\n",
        "    def _calculate_path_complexity(self):\n",
        "        \"\"\"Estimate complexity based on path length from START to EXIT\"\"\"\n",
        "        visited = np.zeros((self.board_size, self.board_size), dtype=bool)\n",
        "        queue = [(self.start_pos, 0)]\n",
        "        visited[self.start_pos[1], self.start_pos[0]] = True\n",
        "        path_lengths = []\n",
        "\n",
        "        while queue:\n",
        "            (x, y), dist = queue.pop(0)\n",
        "            if (x, y) == self.exit_pos:\n",
        "                path_lengths.append(dist)\n",
        "                continue\n",
        "\n",
        "            for dx, dy in [(0, -1), (1, 0), (0, 1), (-1, 0)]:\n",
        "                nx, ny = x + dx, y + dy\n",
        "                if (self.playable_start_x <= nx <= self.playable_end_x and\n",
        "                    self.playable_start_y <= ny <= self.playable_end_y and\n",
        "                    not visited[ny, nx] and self.grid[ny][nx] != WALL):\n",
        "                    visited[ny, nx] = True\n",
        "                    queue.append(((nx, ny), dist + 1))\n",
        "\n",
        "        if not path_lengths:\n",
        "            return 0\n",
        "\n",
        "        avg_path_length = sum(path_lengths) / len(path_lengths)\n",
        "        return avg_path_length / (self.playable_width + self.playable_height)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPm7LAwFEnPR"
      },
      "outputs": [],
      "source": [
        "def train_dungeon_generator(num_episodes=1000, model_path=\"dungeon_rl_model.pth\"):\n",
        "    \"\"\"Train a single RL model to generate levels for all difficulties.\"\"\"\n",
        "    envs = {d: DungeonEnvironment(d) for d in range(1, 11)}  # One environment per difficulty\n",
        "\n",
        "    tile_types = len(envs[1].element_types)\n",
        "    grid_size = 20 * 20\n",
        "    state_size = grid_size * tile_types + 2  # One-hot grid + cursor\n",
        "    action_size = 9  # 4 move + 5 place\n",
        "\n",
        "    agent = DungeonAgent(state_size=state_size, action_size=action_size)\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        difficulty = random.randint(1, 10)\n",
        "        env = envs[difficulty]\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "\n",
        "        if episode % 50 == 0:\n",
        "            print(f\"Episode {episode}, Epsilon: {agent.epsilon:.3f}, Difficulty: {difficulty}\")\n",
        "\n",
        "    torch.save(agent.qnetwork.state_dict(), model_path)\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "    return agent, envs\n",
        "\n",
        "\n",
        "def generate_dungeon_with_model(agent, difficulty):\n",
        "    \"\"\"Generate a level using a trained RL model with added randomness.\"\"\"\n",
        "    env = DungeonEnvironment(difficulty)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.act(state, eval_mode=True)\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            action = random.randint(0, 8)  # Explore randomly\n",
        "\n",
        "        state, _, done = env.step(action)\n",
        "\n",
        "    return env.grid\n",
        "\n",
        "\n",
        "def visualize_dungeon(grid):\n",
        "    \"\"\"Display dungeon grid using matplotlib.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    for y in range(grid.shape[0]):\n",
        "        for x in range(grid.shape[1]):\n",
        "            rect = plt.Rectangle(\n",
        "                (x, grid.shape[0] - y - 1), 1, 1,\n",
        "                facecolor=COLOR_MAP[grid[y, x]],\n",
        "                edgecolor='black'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    ax.set_xlim(0, grid.shape[1])\n",
        "    ax.set_ylim(0, grid.shape[0])\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.title(\"Generated Dungeon\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDmkFgIBKmQt"
      },
      "outputs": [],
      "source": [
        "def load_trained_agent(model_path=\"/content/drive/MyDrive/FAI/dungeon_rl_model.pth\"):\n",
        "    \"\"\"Load the trained model weights into a new agent.\"\"\"\n",
        "    grid_size = 20 * 20\n",
        "    tile_types = len(COLOR_MAP)  # safer than hardcoding 7\n",
        "    state_size = grid_size * tile_types + 2  # one-hot grid + cursor\n",
        "    action_size = 9  # 4 move + 5 place\n",
        "\n",
        "    agent = DungeonAgent(state_size=state_size, action_size=action_size)\n",
        "    agent.qnetwork.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    agent.qnetwork.eval()\n",
        "\n",
        "    print(f\"Model loaded from: {model_path}\")\n",
        "    return agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CA9KajnmEoQm",
        "outputId": "e65221c1-32d7-453b-b78e-c0a95f03f113"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a93204d8a31c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train and Visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrained_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_envs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dungeon_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgenerated_dungeon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dungeon_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvisualize_dungeon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_dungeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8703c6eedd33>\u001b[0m in \u001b[0;36mtrain_dungeon_generator\u001b[0;34m(num_episodes, model_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bb282e4f86ad>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bb282e4f86ad>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_expected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Dropout\n",
        "# Train and Visualize\n",
        "if __name__ == \"__main__\":\n",
        "    trained_agent, trained_envs = train_dungeon_generator(num_episodes=500)\n",
        "    generated_dungeon = generate_dungeon_with_model(trained_agent, 7)\n",
        "    visualize_dungeon(generated_dungeon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fByapT5CcOtd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "3a993827-b2d4-4faf-e414-9bd725d61ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difficulty: 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "difficulty = 10\n",
        "print(f\"Difficulty: {difficulty}\")\n",
        "generated_dungeon = generate_dungeon_with_model(trained_agent, difficulty)\n",
        "visualize_dungeon(generated_dungeon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "rTRpKz_FWuAo",
        "outputId": "25a92cc0-b164-4f45-fb10-5467ce0fa2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from: /content/drive/MyDrive/FAI/dungeon_rl_model.pth\n",
            "Difficulty: 8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load model before generating dungeons\n",
        "agent = load_trained_agent(\"/content/drive/MyDrive/FAI/dungeon_rl_model.pth\")  # Ensure same architecture\n",
        "\n",
        "# Generate dungeon using the loaded model\n",
        "difficulty = 8\n",
        "print(f\"Difficulty: {difficulty}\")\n",
        "generated_dungeon = generate_dungeon_with_model(agent, difficulty)\n",
        "visualize_dungeon(generated_dungeon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WxzZ639KcAu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}